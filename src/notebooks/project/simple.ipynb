{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from duckietown.components.duckiebot import MotorsDriverComponent\n",
    "\n",
    "from typing import Optional\n",
    "from duckietown.components.duckiebot import WheelEncoderDriverComponent\n",
    "\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "\n",
    "# TODO: change this to the name of your Duckiebot\n",
    "VEHICLE_NAME: str = \"yanniduck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DuckiebotDetection():\n",
    "    \"\"\"\n",
    "    This is an example of a component that flips an image vertically.\n",
    "\n",
    "    Args:\n",
    "        axis: int       Axis along which the image is flipped. 0 = Vertical, 1 = Horizontal\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model = self.load_model()\n",
    "        self.classes = self.model.names\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"\\n\\nDevice Used:\",self.device)\n",
    "\n",
    "    def infer(self, bgr):\n",
    "\n",
    "        results = self.score_frame(bgr)\n",
    "        bgr = self.plot_boxes(results, bgr)\n",
    "        return results, bgr\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads Yolo5 model from pytorch hub.\n",
    "        :return: Trained Pytorch model.\n",
    "        \"\"\"\n",
    "        this_dir: str = os.path.abspath('')\n",
    "        assets_dir: str = os.path.join(this_dir, \"..\", \"..\", \"assets\")\n",
    "        model = torch.hub.load(os.path.join(assets_dir, \"yolov5\"), 'custom', path=os.path.join(assets_dir, \"model/model.pt\"), source='local') \n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Takes a single frame as input, and scores the frame using yolo5 model.\n",
    "        :param frame: input frame in numpy/list/tuple format.\n",
    "        :return: Labels and Coordinates of objects detected by model in the frame.\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        frame = [frame]\n",
    "        results = self.model(frame)\n",
    "     \n",
    "        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n",
    "        return labels, cord\n",
    "\n",
    "    def class_to_label(self, x):\n",
    "        \"\"\"\n",
    "        For a given label value, return corresponding string label.\n",
    "        :param x: numeric label\n",
    "        :return: corresponding string label\n",
    "        \"\"\"\n",
    "        return self.classes[int(x)]\n",
    "\n",
    "    def plot_boxes(self, results, frame,  confidence_threshold = 0.2):\n",
    "        \"\"\"\n",
    "        Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "        :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "        :param frame: Frame which has been scored.\n",
    "        :return: Frame with bounding boxes and labels ploted on it.\n",
    "        \"\"\"\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= confidence_threshold:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "                bgr = (0, 255, 0)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)\n",
    "                cv2.putText(frame, self.class_to_label(labels[i]), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def results_to_bounding_boxes(self, results, frame, confidence_threshold = 0.2):\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "\n",
    "        bounding_boxes = []\n",
    "        cropped_images = []\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= confidence_threshold:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "\n",
    "                # Calculate center of the rectangle\n",
    "                center_x = (x1 + x2) / 2.0 / x_shape\n",
    "                center_y = (y1 + y2) / 2.0 / y_shape\n",
    "\n",
    "                area = abs(x1-x2) * abs(y1-y2)\n",
    "                if area > 0.07:\n",
    "                    bounding_box = [x1, y1, x2, y2, center_x, center_y]\n",
    "                    bounding_boxes.append(bounding_box)\n",
    "                    cropped_images.append(frame[y1:y2,x1:x2])\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        return bounding_boxes,cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROS...\n",
      "Using ROS...\n"
     ]
    },
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Set up lane following in this cell\n",
    "\n",
    "import numpy as np\n",
    "from duckietown.types import BGRImage, Queue\n",
    "from duckietown.components import Component\n",
    "import os\n",
    "from duckietown.types import CameraParameters\n",
    "\n",
    "# TODO: change this to the name of your Duckiebot\n",
    "VEHICLE_NAME: str = \"yanniduck\"\n",
    "\n",
    "# TODO: change this to your duckiebot's camera parameters\n",
    "CAMERA_PARAMETERS: CameraParameters = {\n",
    "    \"width\": 640,\n",
    "    \"height\": 480,\n",
    "    \"K\": np.reshape(\n",
    "        [\n",
    "            295.79606866959824,\n",
    "            0.0,\n",
    "            321.2621599038631,\n",
    "            0.0,\n",
    "            299.5389048862878,\n",
    "            241.73616515312332,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            1.0,\n",
    "        ],\n",
    "        (3, 3),\n",
    "    ),\n",
    "    \"D\": [\n",
    "        -0.23543978771661125,\n",
    "        0.03637781479419574,\n",
    "        -0.0033069818601306755,\n",
    "        -0.0012140708179525926,\n",
    "        0.0,\n",
    "    ],\n",
    "    \"P\": np.reshape(\n",
    "        [\n",
    "            201.14027404785156,\n",
    "            0.0,\n",
    "            319.5586620845679,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            239.74398803710938,\n",
    "            237.60151004037834,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            1.0,\n",
    "            0.0,\n",
    "        ],\n",
    "        (3, 4),\n",
    "    ),\n",
    "    \"H\": np.reshape(\n",
    "        [\n",
    "            8.56148231e-03,\n",
    "            2.22480148e-01,\n",
    "            4.24318934e-01,\n",
    "            -5.67022044e-01,\n",
    "            -1.13258040e-03,\n",
    "            6.81113839e-04,\n",
    "            5.80917161e-02,\n",
    "            4.35079347e00,\n",
    "            1.0,\n",
    "        ],\n",
    "        (3, 3),\n",
    "    ),\n",
    "}\n",
    "\n",
    "from typing import List,Union,Tuple\n",
    "\n",
    "state = \"lanefollow\"\n",
    "\n",
    "\n",
    "class MasterComponent(Component[List[float], List[float]]) :\n",
    "    \"\"\"\n",
    "    Componentn that starts and stops lane following\n",
    "\n",
    "    Args:\n",
    "        axis: int       Axis along which the image is flipped. 0 = Vertical, 1 = Horizontal\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MasterComponent, self).__init__()\n",
    "        self.in_pwml_pwmr: Queue[int] = Queue()\n",
    "        self.out_pwml_pwmr: Queue[int] = Queue()\n",
    "\n",
    "\n",
    "    def worker(self):\n",
    "\n",
    "        t_0 = time.time()\n",
    "        while not self.is_shutdown:\n",
    "            #if time.time() - t_0 < 3 and time.time() - t_0 > 0:\n",
    "            if state == \"lanefollow\":\n",
    "                on = True\n",
    "                self.out_pwml_pwmr.put(self.in_pwml_pwmr.get())\n",
    "            #elif on:\n",
    "            else:\n",
    "                navigate_intersection(left_wheel_encoder,right_wheel_encoder,motors, direcc, leds, patterns)\n",
    "\n",
    "                # self.out_pwml_pwmr.put((0,0))\n",
    "                # t_0 = time.time()+3\n",
    "                # on = False\n",
    "\n",
    "# Sensor - Camera\n",
    "from duckietown.components.duckiebot import CameraDriverComponent\n",
    "camera: CameraDriverComponent = CameraDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "from duckietown.components.lane_following import ImageCropComponent\n",
    "image_crop: ImageCropComponent = ImageCropComponent(parameters=CAMERA_PARAMETERS)\n",
    "from duckietown.components.lane_following import LineDetectorComponent\n",
    "line_detector: LineDetectorComponent = LineDetectorComponent()\n",
    "from duckietown.components.lane_following import LaneFilterComponent\n",
    "lane_filter: LaneFilterComponent = LaneFilterComponent(camera_parameters=CAMERA_PARAMETERS)\n",
    "from duckietown.components.lane_following import LaneControllerComponent\n",
    "lane_controller: LaneControllerComponent = LaneControllerComponent()\n",
    "from duckietown.components.lane_following import InverseKinematicsComponent\n",
    "inverse_kinematics: InverseKinematicsComponent = InverseKinematicsComponent()\n",
    "from duckietown.components.lane_following import PWMComponent\n",
    "pwm: PWMComponent = PWMComponent()\n",
    "from duckietown.components.duckiebot import MotorsDriverComponent\n",
    "lane_motors: MotorsDriverComponent = MotorsDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "\n",
    "image_crop.in_bgr.wants(camera.out_bgr)\n",
    "line_detector.in_bgr.wants(image_crop.out_bgr)\n",
    "lane_filter.in_lines.wants(line_detector.out_lines)\n",
    "lane_filter.in_command_time.wants(lane_motors.out_command_time)\n",
    "lane_filter.in_v_omega.wants(lane_controller.out_v_omega)\n",
    "lane_controller.in_d_phi.wants(lane_filter.out_d_phi)\n",
    "inverse_kinematics.in_v_omega.wants(lane_controller.out_v_omega)\n",
    "pwm.in_wl_wr.wants(inverse_kinematics.out_wl_wr)\n",
    "lane_motors.in_pwml_pwmr.wants(pwm.out_pwml_pwmr)\n",
    "\n",
    "from duckietown.components.rendering import ImageRendererComponent\n",
    "from duckietown.components.rendering import intersection_ImageRendererComponent\n",
    "\n",
    "# define components\n",
    "segments: ImageRendererComponent = ImageRendererComponent()\n",
    "belief: ImageRendererComponent = ImageRendererComponent()\n",
    "\n",
    "# connect components\n",
    "segments.in_image.wants(lane_filter.out_segments_image)\n",
    "belief.in_image.wants(lane_filter.out_belief_image)\n",
    "\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "from duckietown.components.base import Component\n",
    "from duckietown.system import System\n",
    "\n",
    "\n",
    "# list of components to run\n",
    "all_lane_follow_components: List[Component] = [\n",
    "    camera,\n",
    "    image_crop,\n",
    "    line_detector,\n",
    "    lane_filter,\n",
    "    lane_controller,\n",
    "    inverse_kinematics,\n",
    "    pwm,\n",
    "    lane_motors,\n",
    "\n",
    "]# create system\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIDController(baseline_left_pwm : float, lr_ref: float, lr_act: float, prev_e_y: float, prev_int_lr: float, delta_t: float):\n",
    "    kp = 0.6\n",
    "    kd = 0\n",
    "    ki = 0.4\n",
    "\n",
    "    e = (lr_ref - lr_act)\n",
    "\n",
    "    e_int = prev_int_lr + e * delta_t\n",
    "    e_int = max(min(e_int,2),-2)\n",
    "\n",
    "    edot = (e-prev_e_y) / delta_t\n",
    "\n",
    "    left_pwm = baseline_left_pwm + kp*e + ki*e_int + kd*edot\n",
    "    \n",
    "    return left_pwm, e, e_int\n",
    "\n",
    "def pose_estimation(R,baseline ,x_prev,y_prev,theta_prev,delta_phi_left,delta_phi_right):\n",
    "\n",
    "    x_curr = x_prev + R*(delta_phi_left+delta_phi_right)*np.cos(theta_prev)/2\n",
    "    y_curr = y_prev + R*(delta_phi_left+delta_phi_right)*np.sin(theta_prev)/2\n",
    "    theta_curr = theta_prev + R*(delta_phi_right-delta_phi_left)/(baseline)\n",
    "\n",
    "\n",
    "    return x_curr, y_curr, theta_curr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def navigate_intersection(lwe, rwe, mot, directions, leds, patterns):\n",
    "def navigate_intersection(lwe, rwe, mot, act, leds, patterns):\n",
    "\n",
    "    wheel_r = 0.0318\n",
    "    wheel_base = 0.035\n",
    "    dl=0\n",
    "    dr=0\n",
    "    ##############\n",
    "    # 0 = straight\n",
    "    # 1 = right\n",
    "    # 2 = left\n",
    "    ##############\n",
    "\n",
    "\n",
    "    ########## AFTER DETECTING AN INTERSECTION:\n",
    "    action = act\n",
    "    # if len(directions)==0:\n",
    "    #     action = 0\n",
    "    # else:\n",
    "    #     action = random.choice(directions)\n",
    "\n",
    "    if action == 0: #drive straight\n",
    "        ref_lr_ratio = 1.02\n",
    "        baseline_right = 0.15\n",
    "        #dur = 2.5\n",
    "    if action == 1: #turn right\n",
    "        ref_lr_ratio = 1.85 # defines turn radius\n",
    "        baseline_right = 0.05 # defines speed\n",
    "    if action == 2: #turn left\n",
    "        ref_lr_ratio = 0.78\n",
    "        baseline_right = 0.28\n",
    "    baseline_left = ref_lr_ratio * baseline_right\n",
    "\n",
    "    #leds.in_pattern.put(patterns[action])\n",
    "    leds.in_pattern.put(patterns[4])\n",
    "\n",
    "    def check_complete(act, ti, tt, th):\n",
    "        if act== 0:\n",
    "            if tt-ti>3.5:\n",
    "                return True\n",
    "        elif act == 1:\n",
    "            if th<-75:\n",
    "                return True\n",
    "        elif act == 2:\n",
    "            if th>75:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    mot.stop()\n",
    "    mot.reset()\n",
    "    mot.start()\n",
    "    \n",
    "    init_ticks_l = lwe.out_ticks.get()\n",
    "    init_ticks_r = rwe.out_ticks.get()\n",
    "\n",
    "    prev_e = 0\n",
    "    prev_int = 0\n",
    "\n",
    "    x_curr,y_curr,theta_curr = 0,0,0\n",
    "\n",
    "    right_pwm = baseline_right\n",
    "    start_time = time.time()\n",
    "    t = start_time\n",
    "    mot.in_pwml_pwmr.put((baseline_left,baseline_right))\n",
    "\n",
    "    time.sleep(0.05)\n",
    "    while not check_complete(action, start_time, t, theta_curr):\n",
    "        #maybe add a sleep here\n",
    "        time.sleep(0.001)\n",
    "\n",
    "        dl = lwe.out_ticks.get()-init_ticks_l\n",
    "        dr = rwe.out_ticks.get()-init_ticks_r\n",
    "        x_curr,y_curr,theta_curr = pose_estimation(wheel_r,wheel_base,0,0,0,dl,dr)\n",
    "\n",
    "        if dr !=0:\n",
    "            lr_ratio = dl/dr\n",
    "        else:\n",
    "            lr_ratio = ref_lr_ratio\n",
    "\n",
    "        delta_t = time.time()-t\n",
    "        t = time.time()\n",
    "        left_pwm, prev_e, prev_int = PIDController(baseline_left, ref_lr_ratio, lr_ratio, prev_e, prev_int, delta_t)\n",
    "\n",
    "        mot.in_pwml_pwmr.put((left_pwm, right_pwm))\n",
    "\n",
    "\n",
    "    state = \"lanefollow\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def intersection_stop_func(image_orig):\n",
    "\n",
    "    h,w,c = image_orig.shape\n",
    "\n",
    "    imgbgr = image_orig\n",
    "\n",
    "    imgrgb = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to HSV for any color-based filtering\n",
    "    imghsv = cv2.cvtColor(imgbgr , cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Most of our operations will be performed on the grayscale version\n",
    "    img = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sigma = 5\n",
    "\n",
    "    # horizont mask\n",
    "    imghsv[:150, :, :] = 255\n",
    "\n",
    "    red_lower_hsv1 = np.array([0, 80, 100])         # CHANGE ME\n",
    "    red_upper_hsv1 = np.array([10, 255, 255])   # CHANGE ME\n",
    "\n",
    "    red_lower_hsv2 = np.array([160, 80, 100])         # CHANGE ME\n",
    "    red_upper_hsv2 = np.array([180, 255, 255])   # CHANGE ME\n",
    "\n",
    "\n",
    "    mask_red1 = cv2.inRange(imghsv, red_lower_hsv1, red_upper_hsv1)\n",
    "    mask_red2 = cv2.inRange(imghsv, red_lower_hsv2, red_upper_hsv2)\n",
    "\n",
    "    mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "\n",
    "    gaussian_filter = cv2.GaussianBlur(mask_red,(0,0), sigma)\n",
    "    mask_intersection = cv2.inRange(gaussian_filter, 50 , 255)\n",
    "\n",
    "    #contours, _ = cv2.findContours(mask_intersection, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_intersection)\n",
    "    red_obj = sorted(stats, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    area_tot = h*w\n",
    " \n",
    "\n",
    "    intersections = []\n",
    "    directions = [False, False, False]\n",
    "    red_lines = 0\n",
    "    stop = False\n",
    "    for i in range(1, min(num_labels,5)):\n",
    "        area = stats[i][4]\n",
    "        y_max = stats[i][2] + stats[i][3]\n",
    "\n",
    "        if (area > area_tot/20) and (y_max > 400):\n",
    "            stop = True\n",
    "        elif area > area_tot/1000:\n",
    "\n",
    "\n",
    "            intersections.append(stats[i])\n",
    "\n",
    "            \n",
    "    if stop:\n",
    "\n",
    "        \n",
    "        sorted_intersections = sorted(intersections, key=lambda x: x[0])#, reverse=True)\n",
    "        for i in range(min(len(sorted_intersections),4)):\n",
    "            x_min = sorted_intersections[i][0]\n",
    "            width = sorted_intersections[i][2]\n",
    "            height = sorted_intersections[i][3]\n",
    "            # if (x_min < w/2) and (width/height > 2.5):\n",
    "            #     directions[1] = True #straight\n",
    "            # elif x_min < w/5:\n",
    "            #     directions[0] = True #left\n",
    "            # elif x_min > w/3:\n",
    "            #     directions[2] = True #right\n",
    "            if (x_min < w/2) and (width/height > 2.5):\n",
    "                directions[0] = True #straight\n",
    "            elif x_min < w/5:\n",
    "                directions[2] = True #left\n",
    "            elif x_min > w/3:\n",
    "                directions[1] = True #right\n",
    "\n",
    "\n",
    "    return mask_intersection, stop, directions\n",
    "\n",
    "def adjust_duckiebot(mask):\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialize the list to store angles\n",
    "    angles = []\n",
    "\n",
    "    # Loop over the contours\n",
    "    for contour in contours:\n",
    "        # Fit a rotated rectangle to the contour\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "\n",
    "        # Extract the angle from the rotated rectangle\n",
    "        angle = rect[2]\n",
    "\n",
    "        # Append the angle to the list\n",
    "        angles.append(angle)\n",
    "\n",
    "    # If there are no contours, return None\n",
    "    if not angles:\n",
    "        return None\n",
    "\n",
    "    # Find the index of the bottommost rectangle\n",
    "    bottommost_index = np.argmax([cv2.boundingRect(cnt)[1] for cnt in contours])\n",
    "\n",
    "    # Return the angle of the bottommost rectangle\n",
    "\n",
    "    ang = angles[bottommost_index]\n",
    "\n",
    "    if ang>45:\n",
    "        ang = ang-90\n",
    "    return ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "default_parameters: dict = {\n",
    "    \"minThreshold\": 5,\n",
    "    \"maxThreshold\": 75,\n",
    "    \"thresholdStep\": 10,\n",
    "\n",
    "    # Filter by Area.\n",
    "    \"filterByArea\": True,\n",
    "    \"minArea\": (8 ** 2) * 3.14,    # min 8 pixels diameter\n",
    "    \"maxArea\": (64 ** 2) * 3.14,   # max 64 pixels diameter\n",
    "\n",
    "    # Filter by Circularity\n",
    "    \"filterByCircularity\": True,\n",
    "    \"minCircularity\": 0.7,\n",
    "\n",
    "    # Filter by Convexity\n",
    "    \"filterByConvexity\": True,\n",
    "    \"minConvexity\": 0.8,\n",
    "\n",
    "    # Filter by Inertia\n",
    "    \"filterByInertia\": False,\n",
    "    \"minInertiaRatio\": 0.05,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def extract_hsv(_bgr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    _hsv = cv2.cvtColor(_bgr, cv2.COLOR_BGR2HSV)\n",
    "    _h = _hsv[:,:,0]\n",
    "    _s = _hsv[:,:,1]\n",
    "    _v = _hsv[:,:,2]\n",
    "    return _h, _s, _v\n",
    "\n",
    "\n",
    "def detect_blobs(_bgr: np.ndarray, **_params) -> Tuple[cv2.KeyPoint, ...]:\n",
    "    # create new configuration that extends the default\n",
    "    _cfg = cv2.SimpleBlobDetector_Params()\n",
    "    for _k, _v in chain(default_parameters.items(), _params.items()):\n",
    "        setattr(_cfg, _k, _v)\n",
    "    # create detector\n",
    "    _detector = cv2.SimpleBlobDetector.create(_cfg)\n",
    "    # find blobs\n",
    "    _keypoints = _detector.detect(_bgr)\n",
    "    print(f\"Found {len(_keypoints)} blobs\")\n",
    "    return _keypoints\n",
    "\n",
    "# Function to check if a color is within a specified range\n",
    "def is_color_within_range(color, target_color, tolerance=30):\n",
    "    lower_bound = np.array([c - tolerance for c in target_color])\n",
    "    upper_bound = np.array([c + tolerance for c in target_color])\n",
    "    return np.all(color >= lower_bound) and np.all(color <= upper_bound)\n",
    "\n",
    "green_range = ([32, 20, 40], [80, 255, 255])\n",
    "purple_range = ([120, 50, 50], [160, 255, 255])\n",
    "blue_range = ([90, 50, 50], [120, 255, 255])\n",
    "red_range = ([0, 50, 50], [30, 255, 255])\n",
    "\n",
    "\n",
    "def is_color_in_range(color, color_range):\n",
    "    lower_bound = np.array(color_range[0], dtype=np.uint8)\n",
    "    upper_bound = np.array(color_range[1], dtype=np.uint8)\n",
    "    color_np = np.array(color, dtype=np.uint8)\n",
    "\n",
    "    mask = cv2.inRange(color_np, lower_bound, upper_bound)\n",
    "    result = cv2.bitwise_and(color_np, color_np, mask=mask)\n",
    "\n",
    "    return np.array_equal(color_np, result)\n",
    "\n",
    "def draw_blobs(_bgr: np.ndarray, _blobs: Tuple[cv2.KeyPoint, ...]) -> np.ndarray:\n",
    "    # draw blobs on the original image\n",
    "    _bgr1 = copy.deepcopy(_bgr)\n",
    "    for kp in _blobs:\n",
    "        _bgr1 = cv2.circle(_bgr1, tuple(map(int, kp.pt)), int(kp.size), (0, 255, 0), 3)\n",
    "    return _bgr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 2023-12-17 Python-3.8.10 torch-2.1.1+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROS...\n",
      "Using ROS...\n",
      "Using ROS...\n",
      "Using ROS...\n",
      "\n",
      "\n",
      "Device Used: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:PIDLaneController:Heading error too large: 1.2727420514756451 > 0.5235987755982988, capped.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 98\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# ind = 0\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# actions = [2,1,0,1]\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m#motors.in_pwml_pwmr.put((0.15,0.15))\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     mask,stopp,direc \u001b[38;5;241m=\u001b[39m intersection_stop_func(\u001b[43mcamera\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_bgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     99\u001b[0m     leds\u001b[38;5;241m.\u001b[39min_pattern\u001b[38;5;241m.\u001b[39mput(white)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stopp:\n",
      "File \u001b[0;32m/code/intersection-navigation/packages/duckietown/types.py:88\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m         item: Any \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     item: Any \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proxied\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m     89\u001b[0m \u001b[39m# we pass the dummy to the queue to unlock them and make them exit\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m item \u001b[39mis\u001b[39;00m SHUTDOWN_DUMMY:\n\u001b[1;32m     91\u001b[0m     \u001b[39m# re-add to the queue to wake others\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/queue.py:170\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    171\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from duckietown.components.duckiebot import CameraDriverComponent\n",
    "from duckietown.components.rendering import intersection_ImageRendererComponent\n",
    "# from intersection_stop import intersection_stop_func, adjust_duckiebot\n",
    "from duckietown.components.duckiebot import LEDsPattern, LEDsDriverComponent\n",
    "from typing import List,Union,Tuple\n",
    "import math\n",
    "\n",
    "# camera: CameraDriverComponent = CameraDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "\n",
    "renderer: intersection_ImageRendererComponent = intersection_ImageRendererComponent()\n",
    "renderer.in_image.wants(camera.out_bgr)\n",
    "\n",
    "led_renderer: ImageRendererComponent = intersection_ImageRendererComponent()\n",
    "\n",
    "\n",
    "left_wheel_encoder: WheelEncoderDriverComponent = WheelEncoderDriverComponent(vehicle_name=VEHICLE_NAME, side=\"left\")\n",
    "right_wheel_encoder: WheelEncoderDriverComponent = WheelEncoderDriverComponent(vehicle_name=VEHICLE_NAME, side=\"right\")\n",
    "\n",
    "left_wheel_encoder.start()\n",
    "right_wheel_encoder.start()\n",
    "\n",
    "from duckietown.components.duckiebot import LEDsPattern, LEDsDriverComponent\n",
    "\n",
    "leds: LEDsDriverComponent = LEDsDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "leds.start()\n",
    "\n",
    "motors: MotorsDriverComponent = MotorsDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "motors.start()\n",
    "\n",
    "# camera.start()\n",
    "renderer.start()\n",
    "led_renderer.start()\n",
    "\n",
    "\n",
    "\n",
    "################################# Defining LED Colors\n",
    "r,g,b=0,0,1\n",
    "# define new pattern\n",
    "intensity: float = 0.4\n",
    "straight_pattern: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "r,g,b=0,0.9,0\n",
    "# define new pattern\n",
    "intensity: float = 0.4\n",
    "right_pattern: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "# define new pattern\n",
    "r,g,b=0.9,0,0\n",
    "intensity: float = 0.4\n",
    "left_pattern: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "r,g,b=1,1,1\n",
    "intensity: float = 0.4\n",
    "white: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "r,g,b=1,0,1\n",
    "intensity: float = 0.4\n",
    "purple: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "patterns = [straight_pattern,right_pattern,left_pattern, white, purple]\n",
    "####################################################################################\n",
    "\n",
    "duckiebot_detection = DuckiebotDetection()\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "for component in all_lane_follow_components:\n",
    "    component.start()\n",
    "\n",
    "# ind = 0\n",
    "# actions = [2,1,0,1]\n",
    "while True:\n",
    "    #motors.in_pwml_pwmr.put((0.15,0.15))\n",
    "    mask,stopp,direc = intersection_stop_func(camera.out_bgr.get())\n",
    "    leds.in_pattern.put(white)\n",
    "\n",
    "    if stopp:\n",
    "        lane_motors.stop()\n",
    "\n",
    "        angle = adjust_duckiebot(mask)\n",
    "        t0 = time.time()\n",
    "        while abs(angle)>3 and time.time()-t0<1:\n",
    "            #print(angle)\n",
    "            if angle>0:\n",
    "                motors.in_pwml_pwmr.put((0.07,0))\n",
    "            else:\n",
    "                motors.in_pwml_pwmr.put((0,0.07))\n",
    "            angle = adjust_duckiebot(mask)\n",
    "            mask,stopp,direc = intersection_stop_func(camera.out_bgr.get())\n",
    "\n",
    "\n",
    "        ### stop at red line\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        ### move up to red line\n",
    "        motors.in_pwml_pwmr.put((0.2,0.19))\n",
    "        time.sleep(0.7)\n",
    "        \n",
    "        ### stop at red line\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        time.sleep(0.05)\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        time.sleep(0.05)\n",
    "\n",
    "        direcc = [index for index, value in enumerate(direc) if value]\n",
    "        if len(direcc)<1:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = random.choice(direcc)\n",
    "        leds.in_pattern.put(patterns[action])\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "        right_bot = True\n",
    "        moving_bot = True\n",
    "        \n",
    "        while right_bot:# or moving_bot:\n",
    "        #while right_bot:\n",
    "            # results, bgr = duckiebot_detection.infer(camera.out_bgr.get())\n",
    "            \n",
    "            # bounding_box_list, cropped_images_list = duckiebot_detection.results_to_bounding_boxes(results, bgr, confidence_threshold=0.3)\n",
    "\n",
    "            # left_bot = []\n",
    "            # center_bot = []\n",
    "            # right_bot = []\n",
    "\n",
    "            # for box in bounding_box_list:\n",
    "            #     if box[4] < 1/7:\n",
    "            #         left_bot.append(box)\n",
    "            #     elif box[4] < 4/7:\n",
    "            #         center_bot.append(box)\n",
    "            #     else:\n",
    "            #         right_bot.append(box)\n",
    "\n",
    "            # for img in cropped_images_list:\n",
    "            #     _, s, _ = extract_hsv(img)\n",
    "            #     blobs: Tuple[cv2.KeyPoint, ...] = detect_blobs(\n",
    "            #         s,\n",
    "            #         # # ---- generic\n",
    "            #         #minThreshold=10,\n",
    "            #         # maxThreshold=75,\n",
    "            #         # thresholdStep=10,\n",
    "            #         # # ---- filter by area\n",
    "            #         # filterByArea=True,\n",
    "            #         # minArea=(8 ** 2) * 3.14,\n",
    "            #         # maxArea=(64 ** 2) * 3.14,\n",
    "            #         # # ---- filter by circularity\n",
    "            #         # filterByCircularity=True,\n",
    "            #         # minCircularity=0.7,\n",
    "            #         # # ---- filter by convexity\n",
    "            #         filterByConvexity=True,\n",
    "            #         minConvexity=0.8,\n",
    "            #         # # ---- filter by inertia\n",
    "            #         # filterByInertia=False,\n",
    "            #         # minInertiaRatio=0.05,\n",
    "            #     )\n",
    "\n",
    "            #     assigned_color = \"\"\n",
    "            #     if blobs:\n",
    "            #         biggest_blob = max(blobs, key=lambda x: x.size)\n",
    "\n",
    "            #         x,y = int(biggest_blob.pt[0]), int(biggest_blob.pt[1])\n",
    "            #         color = img[x,y]\n",
    "\n",
    "            #         # Check if the color is within the defined range for each potential color\n",
    "            #         if is_color_within_range(color, green_range):\n",
    "            #             assigned_color = \"Green\"\n",
    "            #         # elif is_color_within_range(color, purple_range[0], tolerance=30):\n",
    "            #         #     assigned_color = \"Purple\"\n",
    "            #         # elif is_color_within_range(color, blue_range[0], tolerance=30):\n",
    "            #         #     assigned_color = \"Blue\"\n",
    "            #         # elif is_color_within_range(color, red_range[0], tolerance=30):\n",
    "            #         #     assigned_color = \"Red\"\n",
    "            #         else:\n",
    "            #             assigned_color = \"Unknown\"\n",
    "\n",
    "            #     if assigned_color == \"Green\":\n",
    "            #         moving_bot = True\n",
    "            #     else:\n",
    "            #         moving_bot = False\n",
    "            #     led_renderer.in_image.put(draw_blobs(img,blobs))\n",
    "                        \n",
    "\n",
    "                        \n",
    "                        \n",
    "            if not right_bot: #and not moving_bot:\n",
    "            #if not right_bot and not moving_bot:\n",
    "                time.sleep(3)\n",
    "\n",
    "                ### choose direction, and execute action\n",
    "\n",
    "                #direcc = [actions[ind]]\n",
    "                #navigate_intersection(left_wheel_encoder,right_wheel_encoder,motors, direcc, leds, patterns)\n",
    "                navigate_intersection(left_wheel_encoder,right_wheel_encoder,motors, action, leds, patterns)\n",
    "\n",
    "                stopp = False\n",
    "                #ind = ind + 1\n",
    "                \n",
    "                ### restart lane following\n",
    "                lane_motors.reset()\n",
    "                lane_motors.start()\n",
    "\n",
    "\n",
    "\n",
    "camera.stop()\n",
    "renderer.stop()\n",
    "motors.stop()\n",
    "left_wheel_encoder.stop()\n",
    "right_wheel_encoder.stop()\n",
    " \n",
    "\n",
    "\n",
    "#navigate_intersection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in all_lane_follow_components:\n",
    "    component.stop()\n",
    "    \n",
    "camera.stop()\n",
    "renderer.stop()\n",
    "motors.stop()\n",
    "left_wheel_encoder.stop()\n",
    "right_wheel_encoder.stop()\n",
    "leds.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
