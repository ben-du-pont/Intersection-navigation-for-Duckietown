{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from duckietown.components.duckiebot import MotorsDriverComponent\n",
    "\n",
    "from typing import Optional\n",
    "from duckietown.components.duckiebot import WheelEncoderDriverComponent\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "# TODO: change this to the name of your Duckiebot\n",
    "VEHICLE_NAME: str = \"stubbornduck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DuckiebotDetection():\n",
    "    \"\"\"\n",
    "    This is an example of a component that flips an image vertically.\n",
    "\n",
    "    Args:\n",
    "        axis: int       Axis along which the image is flipped. 0 = Vertical, 1 = Horizontal\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model = self.load_model()\n",
    "        self.classes = self.model.names\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"\\n\\nDevice Used:\",self.device)\n",
    "\n",
    "    def infer(self, bgr):\n",
    "\n",
    "        results = self.score_frame(bgr)\n",
    "        bgr = self.plot_boxes(results, bgr)\n",
    "        return results, bgr\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads Yolo5 model from pytorch hub.\n",
    "        :return: Trained Pytorch model.\n",
    "        \"\"\"\n",
    "        this_dir: str = os.path.abspath('')\n",
    "        assets_dir: str = os.path.join(this_dir, \"..\", \"..\", \"assets\")\n",
    "        model = torch.hub.load(os.path.join(assets_dir, \"yolov5\"), 'custom', path=os.path.join(assets_dir, \"model/model.pt\"), source='local') \n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Takes a single frame as input, and scores the frame using yolo5 model.\n",
    "        :param frame: input frame in numpy/list/tuple format.\n",
    "        :return: Labels and Coordinates of objects detected by model in the frame.\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        frame = [frame]\n",
    "        results = self.model(frame)\n",
    "     \n",
    "        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n",
    "        return labels, cord\n",
    "\n",
    "    def class_to_label(self, x):\n",
    "        \"\"\"\n",
    "        For a given label value, return corresponding string label.\n",
    "        :param x: numeric label\n",
    "        :return: corresponding string label\n",
    "        \"\"\"\n",
    "        return self.classes[int(x)]\n",
    "\n",
    "    def plot_boxes(self, results, frame,  confidence_threshold = 0.2):\n",
    "        \"\"\"\n",
    "        Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "        :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "        :param frame: Frame which has been scored.\n",
    "        :return: Frame with bounding boxes and labels ploted on it.\n",
    "        \"\"\"\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= confidence_threshold:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "                bgr = (0, 255, 0)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)\n",
    "                cv2.putText(frame, self.class_to_label(labels[i]), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def results_to_bounding_boxes(self, results, frame, confidence_threshold = 0.2):\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "\n",
    "        bounding_boxes = []\n",
    "\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= confidence_threshold:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "\n",
    "                # Calculate center of the rectangle\n",
    "                center_x = (x1 + x2) / 2.0 / x_shape\n",
    "                center_y = (y1 + y2) / 2.0 / y_shape\n",
    "\n",
    "                area = abs(x1-x2) * abs(y1-y2)\n",
    "                if area > 0.07:\n",
    "                    bounding_box = [x1, y1, x2, y2, center_x, center_y]\n",
    "                    bounding_boxes.append(bounding_box)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROS...\n",
      "Using ROS...\n"
     ]
    },
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Set up lane following in this cell\n",
    "\n",
    "import numpy as np\n",
    "from duckietown.types import BGRImage, Queue\n",
    "from duckietown.components import Component\n",
    "import os\n",
    "from duckietown.types import CameraParameters\n",
    "\n",
    "# TODO: change this to the name of your Duckiebot\n",
    "\n",
    "# TODO: change this to your duckiebot's camera parameters\n",
    "CAMERA_PARAMETERS: CameraParameters = {\n",
    "    \"width\": 640,\n",
    "    \"height\": 480,\n",
    "    \"K\": np.reshape(\n",
    "        [\n",
    "            295.79606866959824,\n",
    "            0.0,\n",
    "            321.2621599038631,\n",
    "            0.0,\n",
    "            299.5389048862878,\n",
    "            241.73616515312332,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            1.0,\n",
    "        ],\n",
    "        (3, 3),\n",
    "    ),\n",
    "    \"D\": [\n",
    "        -0.23543978771661125,\n",
    "        0.03637781479419574,\n",
    "        -0.0033069818601306755,\n",
    "        -0.0012140708179525926,\n",
    "        0.0,\n",
    "    ],\n",
    "    \"P\": np.reshape(\n",
    "        [\n",
    "            201.14027404785156,\n",
    "            0.0,\n",
    "            319.5586620845679,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            239.74398803710938,\n",
    "            237.60151004037834,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            1.0,\n",
    "            0.0,\n",
    "        ],\n",
    "        (3, 4),\n",
    "    ),\n",
    "    \"H\": np.reshape(\n",
    "        [\n",
    "            8.56148231e-03,\n",
    "            2.22480148e-01,\n",
    "            4.24318934e-01,\n",
    "            -5.67022044e-01,\n",
    "            -1.13258040e-03,\n",
    "            6.81113839e-04,\n",
    "            5.80917161e-02,\n",
    "            4.35079347e00,\n",
    "            1.0,\n",
    "        ],\n",
    "        (3, 3),\n",
    "    ),\n",
    "}\n",
    "\n",
    "from typing import List,Union,Tuple\n",
    "\n",
    "state = \"lanefollow\"\n",
    "\n",
    "\n",
    "class MasterComponent(Component[List[float], List[float]]) :\n",
    "    \"\"\"\n",
    "    Componentn that starts and stops lane following\n",
    "\n",
    "    Args:\n",
    "        axis: int       Axis along which the image is flipped. 0 = Vertical, 1 = Horizontal\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MasterComponent, self).__init__()\n",
    "        self.in_pwml_pwmr: Queue[int] = Queue()\n",
    "        self.out_pwml_pwmr: Queue[int] = Queue()\n",
    "\n",
    "\n",
    "    def worker(self):\n",
    "\n",
    "        t_0 = time.time()\n",
    "        while not self.is_shutdown:\n",
    "            #if time.time() - t_0 < 3 and time.time() - t_0 > 0:\n",
    "            if state == \"lanefollow\":\n",
    "                on = True\n",
    "                self.out_pwml_pwmr.put(self.in_pwml_pwmr.get())\n",
    "            #elif on:\n",
    "            else:\n",
    "                navigate_intersection(left_wheel_encoder,right_wheel_encoder,motors, direcc, leds, patterns)\n",
    "\n",
    "                # self.out_pwml_pwmr.put((0,0))\n",
    "                # t_0 = time.time()+3\n",
    "                # on = False\n",
    "\n",
    "# Sensor - Camera\n",
    "from duckietown.components.duckiebot import CameraDriverComponent\n",
    "camera: CameraDriverComponent = CameraDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "from duckietown.components.lane_following import ImageCropComponent\n",
    "image_crop: ImageCropComponent = ImageCropComponent(parameters=CAMERA_PARAMETERS)\n",
    "from duckietown.components.lane_following import LineDetectorComponent\n",
    "line_detector: LineDetectorComponent = LineDetectorComponent()\n",
    "from duckietown.components.lane_following import LaneFilterComponent\n",
    "lane_filter: LaneFilterComponent = LaneFilterComponent(camera_parameters=CAMERA_PARAMETERS)\n",
    "from duckietown.components.lane_following import LaneControllerComponent\n",
    "lane_controller: LaneControllerComponent = LaneControllerComponent()\n",
    "from duckietown.components.lane_following import InverseKinematicsComponent\n",
    "inverse_kinematics: InverseKinematicsComponent = InverseKinematicsComponent()\n",
    "from duckietown.components.lane_following import PWMComponent\n",
    "pwm: PWMComponent = PWMComponent()\n",
    "from duckietown.components.duckiebot import MotorsDriverComponent\n",
    "lane_motors: MotorsDriverComponent = MotorsDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "\n",
    "image_crop.in_bgr.wants(camera.out_bgr)\n",
    "line_detector.in_bgr.wants(image_crop.out_bgr)\n",
    "lane_filter.in_lines.wants(line_detector.out_lines)\n",
    "lane_filter.in_command_time.wants(lane_motors.out_command_time)\n",
    "lane_filter.in_v_omega.wants(lane_controller.out_v_omega)\n",
    "lane_controller.in_d_phi.wants(lane_filter.out_d_phi)\n",
    "inverse_kinematics.in_v_omega.wants(lane_controller.out_v_omega)\n",
    "pwm.in_wl_wr.wants(inverse_kinematics.out_wl_wr)\n",
    "lane_motors.in_pwml_pwmr.wants(pwm.out_pwml_pwmr)\n",
    "\n",
    "from duckietown.components.rendering import ImageRendererComponent\n",
    "from duckietown.components.rendering import intersection_ImageRendererComponent\n",
    "\n",
    "# define components\n",
    "segments: ImageRendererComponent = ImageRendererComponent()\n",
    "belief: ImageRendererComponent = ImageRendererComponent()\n",
    "\n",
    "# connect components\n",
    "segments.in_image.wants(lane_filter.out_segments_image)\n",
    "belief.in_image.wants(lane_filter.out_belief_image)\n",
    "\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "from duckietown.components.base import Component\n",
    "from duckietown.system import System\n",
    "\n",
    "\n",
    "# list of components to run\n",
    "all_lane_follow_components: List[Component] = [\n",
    "    camera,\n",
    "    image_crop,\n",
    "    line_detector,\n",
    "    lane_filter,\n",
    "    lane_controller,\n",
    "    inverse_kinematics,\n",
    "    pwm,\n",
    "    lane_motors,\n",
    "\n",
    "]# create system\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIDController(baseline_left_pwm : float, lr_ref: float, lr_act: float, prev_e_y: float, prev_int_lr: float, delta_t: float):\n",
    "    kp = 0.6\n",
    "    kd = 0\n",
    "    ki = 0.4\n",
    "\n",
    "    e = (lr_ref - lr_act)\n",
    "\n",
    "    e_int = prev_int_lr + e * delta_t\n",
    "    e_int = max(min(e_int,2),-2)\n",
    "\n",
    "    edot = (e-prev_e_y) / delta_t\n",
    "\n",
    "    left_pwm = baseline_left_pwm + kp*e + ki*e_int + kd*edot\n",
    "    \n",
    "    return left_pwm, e, e_int\n",
    "\n",
    "def pose_estimation(R,baseline ,x_prev,y_prev,theta_prev,delta_phi_left,delta_phi_right):\n",
    "\n",
    "    x_curr = x_prev + R*(delta_phi_left+delta_phi_right)*np.cos(theta_prev)/2\n",
    "    y_curr = y_prev + R*(delta_phi_left+delta_phi_right)*np.sin(theta_prev)/2\n",
    "    theta_curr = theta_prev + R*(delta_phi_right-delta_phi_left)/(baseline)\n",
    "\n",
    "\n",
    "    return x_curr, y_curr, theta_curr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def navigate_intersection(lwe, rwe, mot, directions, leds, patterns):\n",
    "def navigate_intersection(lwe, rwe, mot, act, leds, patterns):\n",
    "\n",
    "    wheel_r = 0.0318\n",
    "    wheel_base = 0.035\n",
    "    dl=0\n",
    "    dr=0\n",
    "    ##############\n",
    "    # 0 = straight\n",
    "    # 1 = right\n",
    "    # 2 = left\n",
    "    ##############\n",
    "\n",
    "\n",
    "    ########## AFTER DETECTING AN INTERSECTION:\n",
    "    action = act\n",
    "    # if len(directions)==0:\n",
    "    #     action = 0\n",
    "    # else:\n",
    "    #     action = random.choice(directions)\n",
    "\n",
    "    if action == 0: #drive straight\n",
    "        ref_lr_ratio = 1.02\n",
    "        baseline_right = 0.15\n",
    "        #dur = 2.5\n",
    "    if action == 1: #turn right\n",
    "        ref_lr_ratio = 1.85 # defines turn radius\n",
    "        baseline_right = 0.05 # defines speed\n",
    "    if action == 2: #turn left\n",
    "        ref_lr_ratio = 0.78\n",
    "        baseline_right = 0.28\n",
    "    baseline_left = ref_lr_ratio * baseline_right\n",
    "\n",
    "    #leds.in_pattern.put(patterns[action])\n",
    "    leds.in_pattern.put(patterns[4])\n",
    "\n",
    "    def check_complete(act, ti, tt, th):\n",
    "        if act== 0:\n",
    "            if tt-ti>3.5:\n",
    "                return True\n",
    "        elif act == 1:\n",
    "            if th<-75:\n",
    "                return True\n",
    "        elif act == 2:\n",
    "            if th>75:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    mot.stop()\n",
    "    mot.reset()\n",
    "    mot.start()\n",
    "    \n",
    "    init_ticks_l = lwe.out_ticks.get()\n",
    "    init_ticks_r = rwe.out_ticks.get()\n",
    "\n",
    "    prev_e = 0\n",
    "    prev_int = 0\n",
    "\n",
    "    x_curr,y_curr,theta_curr = 0,0,0\n",
    "\n",
    "    right_pwm = baseline_right\n",
    "    start_time = time.time()\n",
    "    t = start_time\n",
    "    mot.in_pwml_pwmr.put((baseline_left,baseline_right))\n",
    "\n",
    "    time.sleep(0.05)\n",
    "    while not check_complete(action, start_time, t, theta_curr):\n",
    "        #maybe add a sleep here\n",
    "        time.sleep(0.001)\n",
    "\n",
    "        dl = lwe.out_ticks.get()-init_ticks_l\n",
    "        dr = rwe.out_ticks.get()-init_ticks_r\n",
    "        x_curr,y_curr,theta_curr = pose_estimation(wheel_r,wheel_base,0,0,0,dl,dr)\n",
    "\n",
    "        if dr !=0:\n",
    "            lr_ratio = dl/dr\n",
    "        else:\n",
    "            lr_ratio = ref_lr_ratio\n",
    "\n",
    "        delta_t = time.time()-t\n",
    "        t = time.time()\n",
    "        left_pwm, prev_e, prev_int = PIDController(baseline_left, ref_lr_ratio, lr_ratio, prev_e, prev_int, delta_t)\n",
    "\n",
    "        mot.in_pwml_pwmr.put((left_pwm, right_pwm))\n",
    "\n",
    "\n",
    "    state = \"lanefollow\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def intersection_stop_func(image_orig):\n",
    "\n",
    "    h,w,c = image_orig.shape\n",
    "\n",
    "    imgbgr = image_orig\n",
    "\n",
    "    imgrgb = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to HSV for any color-based filtering\n",
    "    imghsv = cv2.cvtColor(imgbgr , cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Most of our operations will be performed on the grayscale version\n",
    "    img = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sigma = 5\n",
    "\n",
    "    # horizont mask\n",
    "    imghsv[:150, :, :] = 255\n",
    "\n",
    "    red_lower_hsv1 = np.array([0, 80, 100])         # CHANGE ME\n",
    "    red_upper_hsv1 = np.array([10, 255, 255])   # CHANGE ME\n",
    "\n",
    "    red_lower_hsv2 = np.array([160, 80, 100])         # CHANGE ME\n",
    "    red_upper_hsv2 = np.array([180, 255, 255])   # CHANGE ME\n",
    "\n",
    "\n",
    "    mask_red1 = cv2.inRange(imghsv, red_lower_hsv1, red_upper_hsv1)\n",
    "    mask_red2 = cv2.inRange(imghsv, red_lower_hsv2, red_upper_hsv2)\n",
    "\n",
    "    mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "\n",
    "    gaussian_filter = cv2.GaussianBlur(mask_red,(0,0), sigma)\n",
    "    mask_intersection = cv2.inRange(gaussian_filter, 50 , 255)\n",
    "\n",
    "    #contours, _ = cv2.findContours(mask_intersection, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_intersection)\n",
    "    red_obj = sorted(stats, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    area_tot = h*w\n",
    " \n",
    "\n",
    "    intersections = []\n",
    "    directions = [False, False, False]\n",
    "    red_lines = 0\n",
    "    stop = False\n",
    "    for i in range(1, min(num_labels,5)):\n",
    "        area = stats[i][4]\n",
    "        y_max = stats[i][2] + stats[i][3]\n",
    "\n",
    "        if (area > area_tot/20) and (y_max > 400):\n",
    "            stop = True\n",
    "        elif area > area_tot/1000:\n",
    "\n",
    "\n",
    "            intersections.append(stats[i])\n",
    "\n",
    "            \n",
    "    if stop:\n",
    "\n",
    "        \n",
    "        sorted_intersections = sorted(intersections, key=lambda x: x[0])#, reverse=True)\n",
    "        for i in range(min(len(sorted_intersections),4)):\n",
    "            x_min = sorted_intersections[i][0]\n",
    "            width = sorted_intersections[i][2]\n",
    "            height = sorted_intersections[i][3]\n",
    "            # if (x_min < w/2) and (width/height > 2.5):\n",
    "            #     directions[1] = True #straight\n",
    "            # elif x_min < w/5:\n",
    "            #     directions[0] = True #left\n",
    "            # elif x_min > w/3:\n",
    "            #     directions[2] = True #right\n",
    "            if (x_min < w/2) and (width/height > 2.5):\n",
    "                directions[0] = True #straight\n",
    "            elif x_min < w/5:\n",
    "                directions[2] = True #left\n",
    "            elif x_min > w/3:\n",
    "                directions[1] = True #right\n",
    "\n",
    "\n",
    "    return mask_intersection, stop, directions\n",
    "\n",
    "def adjust_duckiebot(mask):\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialize the list to store angles\n",
    "    angles = []\n",
    "\n",
    "    # Loop over the contours\n",
    "    for contour in contours:\n",
    "        # Fit a rotated rectangle to the contour\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "\n",
    "        # Extract the angle from the rotated rectangle\n",
    "        angle = rect[2]\n",
    "\n",
    "        # Append the angle to the list\n",
    "        angles.append(angle)\n",
    "\n",
    "    # If there are no contours, return None\n",
    "    if not angles:\n",
    "        return None\n",
    "\n",
    "    # Find the index of the bottommost rectangle\n",
    "    bottommost_index = np.argmax([cv2.boundingRect(cnt)[1] for cnt in contours])\n",
    "\n",
    "    # Return the angle of the bottommost rectangle\n",
    "\n",
    "    ang = angles[bottommost_index]\n",
    "\n",
    "    if ang>45:\n",
    "        ang = ang-90\n",
    "    return ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCAHgAoABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AP5/6KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK/9k=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROS...\n",
      "Using ROS...\n",
      "Using ROS...\n",
      "Using ROS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "YOLOv5 ðŸš€ 2023-12-17 Python-3.8.10 torch-2.1.1+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Device Used: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:PIDLaneController:Heading error too large: 0.5990846632542883 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.6017289494114169 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.7428195240927331 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.7063180113346874 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.5852122456658786 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.6212857894332577 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.7154122492663282 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.7205883929575774 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.8098985865100734 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.5845000718535909 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.6316265103114969 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.6392446603046453 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.5782218566104484 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.803723351025246 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.828956707080108 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.7848559745522141 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.6218758653500308 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.6307782042639896 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.6743064062917602 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.7583806230032226 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.829475591246891 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: 0.8248969836772866 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -1.0089167739035034 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.7265068963127275 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.7394919398002737 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.7685900097771611 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.9159844327299113 > 0.5235987755982988, capped.\n",
      "WARNING:PIDLaneController:Heading error too large: -0.6544984694978745 > 0.5235987755982988, capped.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 173\u001b[0m\n\u001b[1;32m    166\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m#self.state = \"intersection_navigation\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m### choose direction, and execute action\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m#direcc = [actions[ind]]\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m#navigate_intersection(left_wheel_encoder,right_wheel_encoder,motors, direcc, leds, patterns)\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mnavigate_intersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_wheel_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mright_wheel_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmotors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m stopp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#ind = ind + 1\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m### restart lane following\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 71\u001b[0m, in \u001b[0;36mnavigate_intersection\u001b[0;34m(lwe, rwe, mot, act, leds, patterns)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_complete(action, start_time, t, theta_curr):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m#maybe add a sleep here\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m     dl \u001b[38;5;241m=\u001b[39m \u001b[43mlwe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_ticks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39minit_ticks_l\n\u001b[1;32m     72\u001b[0m     dr \u001b[38;5;241m=\u001b[39m rwe\u001b[38;5;241m.\u001b[39mout_ticks\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m-\u001b[39minit_ticks_r\n\u001b[1;32m     73\u001b[0m     x_curr,y_curr,theta_curr \u001b[38;5;241m=\u001b[39m pose_estimation(wheel_r,wheel_base,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,dl,dr)\n",
      "File \u001b[0;32m/code/intersection-navigation/packages/duckietown/types.py:88\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m         item: Any \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     item: Any \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proxied\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m     89\u001b[0m \u001b[39m# we pass the dummy to the queue to unlock them and make them exit\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m item \u001b[39mis\u001b[39;00m SHUTDOWN_DUMMY:\n\u001b[1;32m     91\u001b[0m     \u001b[39m# re-add to the queue to wake others\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/queue.py:170\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    171\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from duckietown.components.duckiebot import CameraDriverComponent\n",
    "from duckietown.components.rendering import intersection_ImageRendererComponent\n",
    "# from intersection_stop import intersection_stop_func, adjust_duckiebot\n",
    "from duckietown.components.duckiebot import LEDsPattern, LEDsDriverComponent\n",
    "from typing import List,Union,Tuple\n",
    "import math\n",
    "\n",
    "# camera: CameraDriverComponent = CameraDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "\n",
    "renderer: intersection_ImageRendererComponent = intersection_ImageRendererComponent()\n",
    "renderer.in_image.wants(camera.out_bgr)\n",
    "\n",
    "\n",
    "left_wheel_encoder: WheelEncoderDriverComponent = WheelEncoderDriverComponent(vehicle_name=VEHICLE_NAME, side=\"left\")\n",
    "right_wheel_encoder: WheelEncoderDriverComponent = WheelEncoderDriverComponent(vehicle_name=VEHICLE_NAME, side=\"right\")\n",
    "\n",
    "left_wheel_encoder.start()\n",
    "right_wheel_encoder.start()\n",
    "\n",
    "from duckietown.components.duckiebot import LEDsPattern, LEDsDriverComponent\n",
    "\n",
    "leds: LEDsDriverComponent = LEDsDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "leds.start()\n",
    "\n",
    "motors: MotorsDriverComponent = MotorsDriverComponent(vehicle_name=VEHICLE_NAME)\n",
    "motors.start()\n",
    "\n",
    "# camera.start()\n",
    "renderer.start()\n",
    "\n",
    "\n",
    "\n",
    "################################# Defining LED Colors\n",
    "r,g,b=0,0,1\n",
    "# define new pattern\n",
    "intensity: float = 0.4\n",
    "straight_pattern: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "r,g,b=0,0.9,0\n",
    "# define new pattern\n",
    "intensity: float = 0.4\n",
    "right_pattern: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "# define new pattern\n",
    "r,g,b=0.9,0,0\n",
    "intensity: float = 0.4\n",
    "left_pattern: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "r,g,b=1,1,1\n",
    "intensity: float = 0.4\n",
    "white: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "\n",
    "r,g,b=1,0,1\n",
    "intensity: float = 0.4\n",
    "purple: LEDsPattern = LEDsPattern(\n",
    "    front_left=(r, g, b, intensity),\n",
    "    front_right=(r, g, b, intensity),\n",
    "    rear_right=(r, g, b, intensity),\n",
    "    rear_left=(r, g, b, intensity),\n",
    ")\n",
    "patterns = [straight_pattern,right_pattern,left_pattern, white, purple]\n",
    "####################################################################################\n",
    "\n",
    "duckiebot_detection = DuckiebotDetection()\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "for component in all_lane_follow_components:\n",
    "    component.start()\n",
    "\n",
    "# ind = 0\n",
    "# actions = [2,1,0,1]\n",
    "while True:\n",
    "    #motors.in_pwml_pwmr.put((0.15,0.15))\n",
    "    mask,stopp,direc = intersection_stop_func(camera.out_bgr.get())\n",
    "    leds.in_pattern.put(white)\n",
    "\n",
    "    if stopp:\n",
    "        lane_motors.stop()\n",
    "\n",
    "        angle = adjust_duckiebot(mask)\n",
    "        t0 = time.time()\n",
    "        while abs(angle)>3 and time.time()-t0<1:\n",
    "            #print(angle)\n",
    "            if angle>0:\n",
    "                motors.in_pwml_pwmr.put((0.07,0))\n",
    "            else:\n",
    "                motors.in_pwml_pwmr.put((0,0.07))\n",
    "            angle = adjust_duckiebot(mask)\n",
    "            mask,stopp,direc = intersection_stop_func(camera.out_bgr.get())\n",
    "\n",
    "\n",
    "        ### stop at red line\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        ### move up to red line\n",
    "        motors.in_pwml_pwmr.put((0.2,0.19))\n",
    "        time.sleep(0.7)\n",
    "        \n",
    "        ### stop at red line\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        time.sleep(0.05)\n",
    "        motors.in_pwml_pwmr.put((0,0))\n",
    "        time.sleep(0.05)\n",
    "\n",
    "        direcc = [index for index, value in enumerate(direc) if value]\n",
    "        if len(direcc)<1:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = random.choice(direcc)\n",
    "        leds.in_pattern.put(patterns[action])\n",
    "\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "        right_bot = True\n",
    "        \n",
    "        while right_bot:\n",
    "            results, bgr = duckiebot_detection.infer(camera.out_bgr.get())\n",
    "            \n",
    "            bounding_box_list = duckiebot_detection.results_to_bounding_boxes(results, bgr, confidence_threshold=0.3)\n",
    "\n",
    "            # RENDER \n",
    "            # _, frame = cv2.imencode('.jpeg', bgr)\n",
    "            # jpeg = frame.tobytes()\n",
    "            # self.infer_renderer._display.update(Image(data=jpeg))\n",
    "\n",
    "            left_bot = []\n",
    "            center_bot = []\n",
    "            right_bot = []\n",
    "\n",
    "            for box in bounding_box_list:\n",
    "                if box[4] < 1/7:\n",
    "                    left_bot.append(box)\n",
    "                elif box[4] < 4/7:\n",
    "                    center_bot.append(box)\n",
    "                else:\n",
    "                    right_bot.append(box)\n",
    "\n",
    "                        \n",
    "                        \n",
    "            if not right_bot:\n",
    "                time.sleep(2)\n",
    "                #self.state = \"intersection_navigation\"\n",
    "\n",
    "                ### choose direction, and execute action\n",
    "\n",
    "                #direcc = [actions[ind]]\n",
    "                #navigate_intersection(left_wheel_encoder,right_wheel_encoder,motors, direcc, leds, patterns)\n",
    "                navigate_intersection(left_wheel_encoder,right_wheel_encoder,motors, action, leds, patterns)\n",
    "\n",
    "                stopp = False\n",
    "                #ind = ind + 1\n",
    "                \n",
    "                ### restart lane following\n",
    "                lane_motors.reset()\n",
    "                lane_motors.start()\n",
    "\n",
    "\n",
    "        #print(right_bot)\n",
    "\n",
    "\n",
    "\n",
    "camera.stop()\n",
    "renderer.stop()\n",
    "motors.stop()\n",
    "left_wheel_encoder.stop()\n",
    "right_wheel_encoder.stop()\n",
    " \n",
    "\n",
    "\n",
    "#navigate_intersection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in all_lane_follow_components:\n",
    "    component.stop()\n",
    "    \n",
    "camera.stop()\n",
    "renderer.stop()\n",
    "motors.stop()\n",
    "left_wheel_encoder.stop()\n",
    "right_wheel_encoder.stop()\n",
    "leds.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
